//! ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬ CLI ëª…ë ¹ì–´.
//!
//! # ì‚¬ìš©ë²•
//!
//! ```bash
//! # í˜„ì¬ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦
//! trader migrate verify
//! trader migrate verify --verbose
//!
//! # í†µí•© ê³„íš ìƒì„± (dry-run)
//! trader migrate consolidate --dry-run
//!
//! # í†µí•© ì‹¤í–‰
//! trader migrate consolidate --output migrations_v2
//!
//! # ì˜ì¡´ì„± ê·¸ë˜í”„ ì‹œê°í™”
//! trader migrate graph --format mermaid > graph.md
//!
//! # ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš© (sqlx ë˜í¼)
//! trader migrate apply --db-url "postgres://..." --dir migrations_v2
//! ```

use std::path::PathBuf;

use trader_core::migration::{
    generate_safety_checklist, DependencyGraph, MigrationAnalyzer, MigrationConsolidator,
    MigrationValidator,
};

/// ë§ˆì´ê·¸ë ˆì´ì…˜ ì„¤ì •
#[derive(Debug, Clone)]
pub struct MigrateConfig {
    /// ë§ˆì´ê·¸ë ˆì´ì…˜ ë””ë ‰í† ë¦¬
    pub migrations_dir: PathBuf,
    /// ì¶œë ¥ ë””ë ‰í† ë¦¬ (í†µí•© ì‹œ)
    pub output_dir: Option<PathBuf>,
    /// ìƒì„¸ ì¶œë ¥
    pub verbose: bool,
    /// Dry-run ëª¨ë“œ
    pub dry_run: bool,
    /// ê·¸ë˜í”„ ì¶œë ¥ í˜•ì‹
    pub graph_format: GraphFormat,
    /// ë°ì´í„°ë² ì´ìŠ¤ URL (apply ì‹œ)
    pub db_url: Option<String>,
}

impl Default for MigrateConfig {
    fn default() -> Self {
        Self {
            migrations_dir: PathBuf::from("migrations"),
            output_dir: None,
            verbose: false,
            dry_run: false,
            graph_format: GraphFormat::Mermaid,
            db_url: None,
        }
    }
}

/// ê·¸ë˜í”„ ì¶œë ¥ í˜•ì‹
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum GraphFormat {
    /// Mermaid ë‹¤ì´ì–´ê·¸ë¨
    Mermaid,
    /// DOT (Graphviz)
    Dot,
    /// í…ìŠ¤íŠ¸
    Text,
}

impl GraphFormat {
    /// ë¬¸ìì—´ì—ì„œ íŒŒì‹±
    pub fn parse(s: &str) -> Option<Self> {
        match s.to_lowercase().as_str() {
            "mermaid" | "md" => Some(Self::Mermaid),
            "dot" | "graphviz" => Some(Self::Dot),
            "text" | "txt" => Some(Self::Text),
            _ => None,
        }
    }
}

/// ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹¤í–‰
pub fn run_verify(config: &MigrateConfig) -> Result<bool, String> {
    println!("\nğŸ” ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì‹œì‘...\n");

    let analyzer = MigrationAnalyzer::new();
    let files = analyzer.scan_directory(&config.migrations_dir)?;

    if files.is_empty() {
        return Err(format!(
            "ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {:?}",
            config.migrations_dir
        ));
    }

    println!("ğŸ“ {} ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ë°œê²¬", files.len());

    if config.verbose {
        for file in &files {
            println!(
                "   {:02}. {} ({} ë¬¸ì¥)",
                file.order,
                file.name,
                file.statements.len()
            );
        }
        println!();
    }

    let validator = MigrationValidator::new(&files);
    let report = validator.validate();

    // ë³´ê³ ì„œ ì¶œë ¥
    println!("{}", report);

    // ì•ˆì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ (ë¬¸ì œê°€ ìˆì„ ë•Œë§Œ)
    if !report.is_valid() || report.warning_count() > 0 {
        println!("{}", generate_safety_checklist(&report));
    }

    if config.verbose {
        // ì˜ì¡´ì„± ê·¸ë˜í”„ ìš”ì•½
        println!("\nğŸ“Š ì˜ì¡´ì„± ê·¸ë˜í”„ ìš”ì•½");
        println!("  ì •ì˜ëœ ê°ì²´: {} ê°œ", report.graph.definitions.len());
        println!("  ì˜ì¡´ ê´€ê³„: {} ê°œ", report.graph.dependencies.len());

        let duplicates = report.graph.find_duplicates();
        if !duplicates.is_empty() {
            println!("\n  âš ï¸ ì¤‘ë³µ ì •ì˜ ê°ì²´:");
            for (obj, locs) in &duplicates {
                let loc_strs: Vec<_> = locs.iter().map(|(f, l)| format!("{}:{}", f, l)).collect();
                println!("    - {}: {}", obj, loc_strs.join(", "));
            }
        }
    }

    Ok(report.is_valid())
}

/// ë§ˆì´ê·¸ë ˆì´ì…˜ í†µí•© ì‹¤í–‰
pub fn run_consolidate(config: &MigrateConfig) -> Result<(), String> {
    println!("\nğŸ“¦ ë§ˆì´ê·¸ë ˆì´ì…˜ í†µí•© ì‹œì‘...\n");

    let analyzer = MigrationAnalyzer::new();
    let files = analyzer.scan_directory(&config.migrations_dir)?;

    if files.is_empty() {
        return Err("ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤".to_string());
    }

    let consolidator = MigrationConsolidator::new();
    let plan = consolidator.plan(&files);

    if config.dry_run {
        // Dry-run ê²°ê³¼ ì¶œë ¥
        println!("{}", consolidator.dry_run(&plan));
        println!("\nâœ… Dry-run ì™„ë£Œ. ì‹¤ì œ ì ìš©í•˜ë ¤ë©´ --dry-run ì œê±° í›„ ì¬ì‹¤í–‰.");
        return Ok(());
    }

    // ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²°ì •
    let output_dir = config
        .output_dir
        .as_ref()
        .cloned()
        .unwrap_or_else(|| PathBuf::from("migrations_v2"));

    // í†µí•© ì‹¤í–‰
    println!("{}", plan);
    consolidator.execute(&plan, &output_dir)?;

    println!("\nâœ… í†µí•© ì™„ë£Œ!");
    println!("   ì¶œë ¥ ë””ë ‰í† ë¦¬: {:?}", output_dir);
    println!("   ìƒì„±ëœ íŒŒì¼: {} ê°œ", plan.files.len());
    println!("   ê°ì†Œìœ¨: {:.1}%", plan.reduction_percentage());

    // ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
    println!("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:");
    println!("   1. í†µí•©ëœ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€í† : cat {:?}/*.sql", output_dir);
    println!(
        "   2. í…ŒìŠ¤íŠ¸ DBì—ì„œ ê²€ì¦: trader migrate apply --db-url <TEST_DB> --dir {:?}",
        output_dir
    );
    println!("   3. ìŠ¤í‚¤ë§ˆ ë¹„êµ í™•ì¸ í›„ ìš´ì˜ ì ìš©");

    Ok(())
}

/// ì˜ì¡´ì„± ê·¸ë˜í”„ ì¶œë ¥
pub fn run_graph(config: &MigrateConfig) -> Result<String, String> {
    let analyzer = MigrationAnalyzer::new();
    let files = analyzer.scan_directory(&config.migrations_dir)?;
    let graph = analyzer.build_dependency_graph(&files);

    let output = match config.graph_format {
        GraphFormat::Mermaid => generate_mermaid_graph(&graph, &files),
        GraphFormat::Dot => generate_dot_graph(&graph, &files),
        GraphFormat::Text => generate_text_graph(&graph, &files),
    };

    Ok(output)
}

/// Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
fn generate_mermaid_graph(
    graph: &DependencyGraph,
    files: &[trader_core::migration::MigrationFile],
) -> String {
    let mut output = String::new();

    output.push_str("```mermaid\n");
    output.push_str("graph TD\n");
    output.push_str("    subgraph \"ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ ì˜ì¡´ì„±\"\n");

    // íŒŒì¼ ë…¸ë“œ
    for file in files {
        output.push_str(&format!(
            "        {}[\"{}\"]\n",
            file.name.replace(['.', '-'], "_"),
            file.name
        ));
    }

    // íŒŒì¼ ê°„ ì˜ì¡´ì„± ì—£ì§€
    for (file, deps) in &graph.file_dependencies {
        for dep in deps {
            output.push_str(&format!(
                "        {} --> {}\n",
                file.replace(['.', '-'], "_"),
                dep.replace(['.', '-'], "_")
            ));
        }
    }

    output.push_str("    end\n");
    output.push_str("```\n\n");

    // ê°ì²´ ì˜ì¡´ì„± (ì£¼ìš” ê°ì²´ë§Œ)
    output.push_str("```mermaid\n");
    output.push_str("graph LR\n");
    output.push_str("    subgraph \"ì£¼ìš” ê°ì²´ ì˜ì¡´ì„±\"\n");

    let mut shown = std::collections::HashSet::new();
    for (obj, deps) in &graph.dependencies {
        if !deps.is_empty() && !obj.starts_with("idx_") && !obj.starts_with("v_") {
            for dep in deps {
                if !dep.starts_with("idx_") && shown.len() < 50 {
                    output.push_str(&format!(
                        "        {} --> {}\n",
                        obj.replace(['.', '-'], "_"),
                        dep.replace(['.', '-'], "_")
                    ));
                    shown.insert((obj.clone(), dep.clone()));
                }
            }
        }
    }

    output.push_str("    end\n");
    output.push_str("```\n");

    output
}

/// DOT ê·¸ë˜í”„ ìƒì„±
fn generate_dot_graph(
    graph: &DependencyGraph,
    files: &[trader_core::migration::MigrationFile],
) -> String {
    let mut output = String::new();

    output.push_str("digraph MigrationDependencies {\n");
    output.push_str("    rankdir=LR;\n");
    output.push_str("    node [shape=box];\n\n");

    // íŒŒì¼ ì„œë¸Œê·¸ë˜í”„
    output.push_str("    subgraph cluster_files {\n");
    output.push_str("        label=\"Migration Files\";\n");
    for file in files {
        output.push_str(&format!("        \"{}\";\n", file.name));
    }
    output.push_str("    }\n\n");

    // íŒŒì¼ ì˜ì¡´ì„±
    for (file, deps) in &graph.file_dependencies {
        for dep in deps {
            output.push_str(&format!("    \"{}\" -> \"{}\";\n", file, dep));
        }
    }

    output.push_str("}\n");

    output
}

/// í…ìŠ¤íŠ¸ ê·¸ë˜í”„ ìƒì„±
fn generate_text_graph(
    graph: &DependencyGraph,
    files: &[trader_core::migration::MigrationFile],
) -> String {
    let mut output = String::new();

    output.push_str("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    output.push_str("                    ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ì¡´ì„± ê·¸ë˜í”„\n");
    output.push_str("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");

    output.push_str("ğŸ“ íŒŒì¼ë³„ ì˜ì¡´ì„±\n");
    output.push_str("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n");

    for file in files {
        output.push_str(&format!("\n{} (ìˆœì„œ: {})\n", file.name, file.order));

        if let Some(deps) = graph.file_dependencies.get(&file.name) {
            if deps.is_empty() {
                output.push_str("  â””â”€â”€ (ì˜ì¡´ì„± ì—†ìŒ)\n");
            } else {
                for dep in deps {
                    output.push_str(&format!("  â””â”€â”€ {}\n", dep));
                }
            }
        } else {
            output.push_str("  â””â”€â”€ (ì˜ì¡´ì„± ì—†ìŒ)\n");
        }
    }

    output.push_str("\n\nğŸ“Š ê°ì²´ ì •ì˜\n");
    output.push_str("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n");

    let mut sorted_defs: Vec<_> = graph.definitions.iter().collect();
    sorted_defs.sort_by_key(|(name, _)| name.as_str());

    for (obj, locations) in sorted_defs {
        if !obj.starts_with("idx_") {
            let loc_strs: Vec<_> = locations
                .iter()
                .map(|(f, l)| format!("{}:{}", f, l))
                .collect();
            output.push_str(&format!("  {} @ {}\n", obj, loc_strs.join(", ")));
        }
    }

    output.push_str("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    output
}

/// ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©
///
/// ì´ í•¨ìˆ˜ëŠ” sqlx migrate run ëª…ë ¹ì„ ë˜í•‘í•©ë‹ˆë‹¤.
/// ì‹¤ì œ ì ìš© ì „ í•­ìƒ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
pub async fn run_apply(config: &MigrateConfig) -> Result<(), String> {
    println!("\nğŸš€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš© ì‹œì‘...\n");

    // 1. ë¨¼ì € ê²€ì¦ ìˆ˜í–‰
    println!("1ï¸âƒ£ ë§ˆì´ê·¸ë ˆì´ì…˜ ê²€ì¦ ì¤‘...");
    let verify_config = MigrateConfig {
        migrations_dir: config.migrations_dir.clone(),
        verbose: false,
        ..Default::default()
    };

    let is_valid = run_verify(&verify_config)?;
    if !is_valid {
        return Err("ê²€ì¦ ì‹¤íŒ¨: ì—ëŸ¬ë¥¼ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.".to_string());
    }

    println!("\nâœ… ê²€ì¦ í†µê³¼\n");

    // 2. ë°ì´í„°ë² ì´ìŠ¤ URL í™•ì¸
    let db_url = config
        .db_url
        .clone()
        .or_else(|| std::env::var("DATABASE_URL").ok())
        .ok_or("DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. --db-url ì˜µì…˜ ì‚¬ìš©")?;

    println!("2ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸...");
    println!(
        "   URL: {}...{}",
        &db_url[..20.min(db_url.len())],
        &db_url[db_url.len().saturating_sub(20)..]
    );

    // 3. sqlx migrate run ì‹¤í–‰
    println!("\n3ï¸âƒ£ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰...");

    let migrations_path = config.migrations_dir.to_string_lossy().to_string();

    let output = std::process::Command::new("sqlx")
        .args([
            "migrate",
            "run",
            "--source",
            &migrations_path,
            "--database-url",
            &db_url,
        ])
        .output()
        .map_err(|e| {
            format!(
                "sqlx ì‹¤í–‰ ì‹¤íŒ¨: {}. sqlx-cliê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.",
                e
            )
        })?;

    if output.status.success() {
        println!("\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš© ì™„ë£Œ!");
        println!("{}", String::from_utf8_lossy(&output.stdout));
        Ok(())
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(format!("ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨:\n{}", stderr))
    }
}

/// ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸
pub async fn run_status(config: &MigrateConfig) -> Result<(), String> {
    let db_url = config
        .db_url
        .clone()
        .or_else(|| std::env::var("DATABASE_URL").ok())
        .ok_or("DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")?;

    let migrations_path = config.migrations_dir.to_string_lossy().to_string();

    let output = std::process::Command::new("sqlx")
        .args([
            "migrate",
            "info",
            "--source",
            &migrations_path,
            "--database-url",
            &db_url,
        ])
        .output()
        .map_err(|e| format!("sqlx ì‹¤í–‰ ì‹¤íŒ¨: {}", e))?;

    println!("{}", String::from_utf8_lossy(&output.stdout));

    if !output.status.success() {
        println!("{}", String::from_utf8_lossy(&output.stderr));
    }

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_graph_format_parse() {
        assert_eq!(GraphFormat::parse("mermaid"), Some(GraphFormat::Mermaid));
        assert_eq!(GraphFormat::parse("DOT"), Some(GraphFormat::Dot));
        assert_eq!(GraphFormat::parse("text"), Some(GraphFormat::Text));
        assert_eq!(GraphFormat::parse("invalid"), None);
    }

    #[test]
    fn test_default_config() {
        let config = MigrateConfig::default();
        assert_eq!(config.migrations_dir, PathBuf::from("migrations"));
        assert!(!config.verbose);
        assert!(!config.dry_run);
    }
}
